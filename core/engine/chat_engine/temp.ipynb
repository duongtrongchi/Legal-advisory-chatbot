{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import tiktoken\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index import (\n",
    "   VectorStoreIndex,\n",
    "   SimpleDirectoryReader,\n",
    "   OpenAIEmbedding,\n",
    "   PromptHelper,\n",
    "   ServiceContext\n",
    ")\n",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.vector_stores import ElasticsearchStore\n",
    "from llama_index.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.schema import QueryBundle\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "from prompts import REWRITE_QUERIES_TEMPLATE, text_qa_template\n",
    "\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['OPENAI_API_KEY']\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "def generate_queries(query: str, num_queries: int = 3):\n",
    "   response = llm.predict(\n",
    "      REWRITE_QUERIES_TEMPLATE, num_queries=num_queries, query=query\n",
    "   )\n",
    "\n",
    "   queries = response.split(\"\\n\")\n",
    "   queries_str = \"\\n\".join(queries)\n",
    "   print(f\"Generated queries:\\n{queries_str}\")\n",
    "   print(\"=\"*100)\n",
    "\n",
    "   return queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChatEngine:\n",
    "    def __init__(self, documents_path=\"../../data/\", new_indexing=False):\n",
    "        self.vector_store = ElasticsearchStore(\n",
    "                                es_url=\"http://localhost:9200\",\n",
    "                                index_name=\"law_index\",\n",
    "                            )\n",
    "        self.node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "            window_size=3,\n",
    "            window_metadata_key=\"window\",\n",
    "            original_text_metadata_key=\"original_text\",\n",
    "        )\n",
    "        self.llm = OpenAI(model='gpt-3.5-turbo', temperature=0.7, max_tokens=256)\n",
    "        self.embed_model = OpenAIEmbedding()\n",
    "        self.prompt_helper = PromptHelper(\n",
    "                                context_window=4096,\n",
    "                                num_output=256,\n",
    "                                chunk_overlap_ratio=0.1,\n",
    "                                chunk_size_limit=None\n",
    "                            )\n",
    "        self.service_context = ServiceContext.from_defaults(\n",
    "                                llm=llm,\n",
    "                                embed_model=self.embed_model,\n",
    "                                node_parser=self.node_parser,\n",
    "                                prompt_helper=self.prompt_helper\n",
    "                            )\n",
    "\n",
    "        self.documents = SimpleDirectoryReader(documents_path).load_data()\n",
    "        self.sentence_nodes = self.node_parser.get_nodes_from_documents(self.documents)\n",
    "        self.storage_context = StorageContext.from_defaults(vector_store=self.vector_store)\n",
    "        self.index = VectorStoreIndex.from_vector_store(\n",
    "            self.vector_store,\n",
    "            storage_context=self.storage_context,\n",
    "            service_context=self.service_context\n",
    "        )\n",
    "        if new_indexing:\n",
    "            self.index = VectorStoreIndex(\n",
    "                self.sentence_nodes,\n",
    "                storage_context=self.storage_context,\n",
    "                service_context=self.service_context,\n",
    "            )\n",
    "\n",
    "\n",
    "    def chat_en(self, queries: list[str], query_origin):\n",
    "\n",
    "        retriever = self.index.as_retriever(\n",
    "            similarity_top_k=3,\n",
    "            # vector_store_query_mode=\"hybrid\",\n",
    "            alpha=0.5,\n",
    "            text_qa_template = text_qa_template\n",
    "        )\n",
    "\n",
    "        # Get all node after retrieval step\n",
    "        retrieved_nodes = []\n",
    "        for query in queries:\n",
    "            retrieved_nodes += retriever.retrieve(query)\n",
    "        retrieved_nodes += retriever.retrieve(query_origin)\n",
    "\n",
    "\n",
    "        # Rerank\n",
    "        query_bundle = QueryBundle(query_origin)\n",
    "\n",
    "\n",
    "        rerank = SentenceTransformerRerank(\n",
    "            top_n = 3,\n",
    "            model = \"BAAI/bge-reranker-base\"\n",
    "        )\n",
    "\n",
    "\n",
    "        retrieved_nodes = rerank.postprocess_nodes(\n",
    "            retrieved_nodes, query_bundle\n",
    "        )\n",
    "\n",
    "        # Replace with sentence window node\n",
    "        postprocessor = MetadataReplacementPostProcessor(\n",
    "            target_metadata_key=\"window\",\n",
    "        )\n",
    "\n",
    "        window_nodes = postprocessor.postprocess_nodes(retrieved_nodes)\n",
    "        for i in window_nodes:\n",
    "            print('REFRENCES: \\n')\n",
    "            print(i.get_score())\n",
    "            print(i.get_content())\n",
    "            print('='*100)\n",
    "\n",
    "\n",
    "        # Generate response with top_k result\n",
    "        context_str = \"\\n\\n\".join([r.get_content() for r in window_nodes])\n",
    "\n",
    "        llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "        response = llm.predict(\n",
    "            text_qa_template, context_str=context_str, query_str=query_origin\n",
    "        )\n",
    "\n",
    "        print(response)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Generated queries:\n",
      "1. Các ngành học phổ biến tại trường đại học Tôn Đức Thắng là gì?\n",
      "2. Có bao nhiêu cơ sở của trường đại học Tôn Đức Thắng và chúng nằm ở đâu?\n",
      "3. Trường đại học Tôn Đức Thắng có những chương trình đào tạo nào được đánh giá cao?\n",
      "====================================================================================================\n",
      "INFO:elastic_transport.transport:GET http://localhost:9200/ [status:200 duration:0.020s]\n",
      "GET http://localhost:9200/ [status:200 duration:0.020s]\n",
      "GET http://localhost:9200/ [status:200 duration:0.020s]\n",
      "GET http://localhost:9200/ [status:200 duration:0.020s]\n",
      "GET http://localhost:9200/ [status:200 duration:0.020s]\n",
      "GET http://localhost:9200/ [status:200 duration:0.020s]\n",
      "GET http://localhost:9200/ [status:200 duration:0.020s]\n",
      "GET http://localhost:9200/ [status:200 duration:0.020s]\n",
      "GET http://localhost:9200/ [status:200 duration:0.020s]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/law_index/_search [status:200 duration:0.053s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.053s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.053s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.053s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.053s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.053s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.053s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.053s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.053s]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/law_index/_search [status:200 duration:0.032s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.032s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.032s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.032s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.032s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.032s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.032s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.032s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.032s]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/law_index/_search [status:200 duration:0.033s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.033s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.033s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.033s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.033s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.033s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.033s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.033s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.033s]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/law_index/_search [status:200 duration:0.030s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.030s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.030s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.030s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.030s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.030s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.030s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.030s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.030s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REFRENCES: \n",
      "\n",
      "0.8300757\n",
      "Có 04 chương trình đạt chuẩn kiểm định FIBAA: Tháng 11/2021, Hội đồng xét công nhận chất lượng của tổ chức FIBAA (Foundation for International Business Administration Accreditation) đã chính thức công nhận và cấp con dấu chất lượng (Quality Seal) cho 4 chương trình đào tạo bậc đại học của Trường Đại học Tôn Đức Thắng (TDTU).  Thời hạn công nhận là 5 năm (2021-2026).  Các chương trình được kiểm định và chứng nhận bởi FIBAA bao gồm: Quan hệ lao động, Quy hoạch vùng và đô thị, Xã hội học, Việt Nam học - chuyên ngành Du lịch và Quản lý du lịch.\n",
      "\n",
      " Các cơ sở của trường đại học Tôn Đức Thắng\n",
      "Trụ sở chính: 19 Nguyễn Hữu Thọ, phường Tân Phong, Quận 7.\n",
      " Phân hiệu Khánh Hòa: Số 22, đường Nguyễn Đình Chiểu, Phường Vĩnh Phước, Thành phố Nha Trang, tỉnh Khánh Hòa.\n",
      " Cơ sở Bảo Lộc: phường Lộc Tiến, Tp Bảo Lộc, Lâm Đồng.\n",
      "\n",
      "====================================================================================================\n",
      "REFRENCES: \n",
      "\n",
      "0.8300757\n",
      "Có 04 chương trình đạt chuẩn kiểm định FIBAA: Tháng 11/2021, Hội đồng xét công nhận chất lượng của tổ chức FIBAA (Foundation for International Business Administration Accreditation) đã chính thức công nhận và cấp con dấu chất lượng (Quality Seal) cho 4 chương trình đào tạo bậc đại học của Trường Đại học Tôn Đức Thắng (TDTU).  Thời hạn công nhận là 5 năm (2021-2026).  Các chương trình được kiểm định và chứng nhận bởi FIBAA bao gồm: Quan hệ lao động, Quy hoạch vùng và đô thị, Xã hội học, Việt Nam học - chuyên ngành Du lịch và Quản lý du lịch.\n",
      "\n",
      " Các cơ sở của trường đại học Tôn Đức Thắng\n",
      "Trụ sở chính: 19 Nguyễn Hữu Thọ, phường Tân Phong, Quận 7.\n",
      " Phân hiệu Khánh Hòa: Số 22, đường Nguyễn Đình Chiểu, Phường Vĩnh Phước, Thành phố Nha Trang, tỉnh Khánh Hòa.\n",
      " Cơ sở Bảo Lộc: phường Lộc Tiến, Tp Bảo Lộc, Lâm Đồng.\n",
      "\n",
      "====================================================================================================\n",
      "REFRENCES: \n",
      "\n",
      "0.8300757\n",
      "Có 04 chương trình đạt chuẩn kiểm định FIBAA: Tháng 11/2021, Hội đồng xét công nhận chất lượng của tổ chức FIBAA (Foundation for International Business Administration Accreditation) đã chính thức công nhận và cấp con dấu chất lượng (Quality Seal) cho 4 chương trình đào tạo bậc đại học của Trường Đại học Tôn Đức Thắng (TDTU).  Thời hạn công nhận là 5 năm (2021-2026).  Các chương trình được kiểm định và chứng nhận bởi FIBAA bao gồm: Quan hệ lao động, Quy hoạch vùng và đô thị, Xã hội học, Việt Nam học - chuyên ngành Du lịch và Quản lý du lịch.\n",
      "\n",
      " Các cơ sở của trường đại học Tôn Đức Thắng\n",
      "Trụ sở chính: 19 Nguyễn Hữu Thọ, phường Tân Phong, Quận 7.\n",
      " Phân hiệu Khánh Hòa: Số 22, đường Nguyễn Đình Chiểu, Phường Vĩnh Phước, Thành phố Nha Trang, tỉnh Khánh Hòa.\n",
      " Cơ sở Bảo Lộc: phường Lộc Tiến, Tp Bảo Lộc, Lâm Đồng.\n",
      "\n",
      "====================================================================================================\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Các cơ sở của trường đại học Tôn Đức Thắng bao gồm:\n",
      "1. Trụ sở chính: 19 Nguyễn Hữu Thọ, phường Tân Phong, Quận 7.\n",
      "2. Phân hiệu Khánh Hòa: Số 22, đường Nguyễn Đình Chiểu, Phường Vĩnh Phước, Thành phố Nha Trang, tỉnh Khánh Hòa.\n",
      "3. Cơ sở Bảo Lộc: phường Lộc Tiến, Tp Bảo Lộc, Lâm Đồng.\n",
      "Các cơ sở của trường đại học Tôn Đức Thắng bao gồm:\n",
      "1. Trụ sở chính: 19 Nguyễn Hữu Thọ, phường Tân Phong, Quận 7.\n",
      "2. Phân hiệu Khánh Hòa: Số 22, đường Nguyễn Đình Chiểu, Phường Vĩnh Phước, Thành phố Nha Trang, tỉnh Khánh Hòa.\n",
      "3. Cơ sở Bảo Lộc: phường Lộc Tiến, Tp Bảo Lộc, Lâm Đồng.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    query = \"Các cơ sở của trường đại học Tôn Đức Thắng?\"\n",
    "    queries = generate_queries(query)\n",
    "    chat = ChatEngine().chat_en(queries, query)\n",
    "\n",
    "    print(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:GET https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/ [status:200 duration:1.004s]\n",
      "GET https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/ [status:200 duration:1.004s]\n",
      "GET https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/ [status:200 duration:1.004s]\n",
      "GET https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/ [status:200 duration:1.004s]\n",
      "GET https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/ [status:200 duration:1.004s]\n",
      "GET https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/ [status:200 duration:1.004s]\n",
      "GET https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/ [status:200 duration:1.004s]\n",
      "GET https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/ [status:200 duration:1.004s]\n",
      "GET https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/ [status:200 duration:1.004s]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:elastic_transport.transport:POST https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/law_bot/_search [status:200 duration:1.134s]\n",
      "POST https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/law_bot/_search [status:200 duration:1.134s]\n",
      "POST https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/law_bot/_search [status:200 duration:1.134s]\n",
      "POST https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/law_bot/_search [status:200 duration:1.134s]\n",
      "POST https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/law_bot/_search [status:200 duration:1.134s]\n",
      "POST https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/law_bot/_search [status:200 duration:1.134s]\n",
      "POST https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/law_bot/_search [status:200 duration:1.134s]\n",
      "POST https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/law_bot/_search [status:200 duration:1.134s]\n",
      "POST https://00dc83bbb5764ce9bd2eb125005067c1.us-central1.gcp.cloud.es.io:443/law_bot/_search [status:200 duration:1.134s]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Tôi là một trợ lý tư vấn pháp luật có tên là Lyly.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import tiktoken\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from llama_index import ServiceContext, LLMPredictor, OpenAIEmbedding, PromptHelper\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.text_splitter import TokenTextSplitter\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores import ElasticsearchStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "\n",
    "\n",
    "from prompts import base_prompt_template\n",
    "\n",
    "documents = SimpleDirectoryReader(\"../../data/\").load_data()\n",
    "\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(\n",
    "  separator=\" \",\n",
    "  chunk_size=1024,\n",
    "  chunk_overlap=20,\n",
    "  tokenizer=tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n",
    ")\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo', temperature=0.7, max_tokens=256)\n",
    "embed_model = OpenAIEmbedding()\n",
    "\n",
    "prompt_helper = PromptHelper(\n",
    "  context_window=4096,\n",
    "  num_output=256,\n",
    "  chunk_overlap_ratio=0.1,\n",
    "  chunk_size_limit=None\n",
    ")\n",
    "\n",
    "\n",
    "vector_store = ElasticsearchStore(\n",
    "  index_name=\"law_bot\",\n",
    "  es_cloud_id=\"a360a60c18784a4288ef610006c3b861:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvJDAwZGM4M2JiYjU3NjRjZTliZDJlYjEyNTAwNTA2N2MxJDQzOTI5MzIyNGNlMjRiZDZhOTRkODYzOWQyZTNlYWJl\",\n",
    "  es_api_key=\"bUR1b3lZMEIzSUxOY1MxYjRvMEQ6ZE9PMS01UGlSSVdvdEhncUVkWmlWQQ==\"\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "  llm=llm,\n",
    "  embed_model=embed_model,\n",
    "  node_parser=node_parser,\n",
    "  prompt_helper=prompt_helper\n",
    ")\n",
    "\n",
    "\n",
    "def indexing_simple_rag(flag=False, path=\"../../data/\"):\n",
    "    index = None\n",
    "    if flag == True:\n",
    "        documents = SimpleDirectoryReader(path).load_data()\n",
    "        index = VectorStoreIndex.from_documents(\n",
    "          documents,\n",
    "          service_context=service_context,\n",
    "          storage_context=storage_context,\n",
    "        )\n",
    "        return index\n",
    "\n",
    "    index = VectorStoreIndex.from_vector_store(\n",
    "            vector_store,\n",
    "            storage_context=storage_context,\n",
    "            service_context=service_context\n",
    "    )\n",
    "    return index\n",
    "\n",
    "\n",
    "def genaration_qa(question, new_index=False, path=\"../../data/\"):\n",
    "  if new_index == True:\n",
    "    index = indexing_simple_rag(flag=new_index, path=path)\n",
    "  else:\n",
    "     index = indexing_simple_rag(flag=False)\n",
    "  query_engine = index.as_query_engine(text_qa_template=base_prompt_template)\n",
    "  response = query_engine.query(question)\n",
    "  return response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   ques = genaration_qa(question=\"Bạn là ai?\")\n",
    "   print(ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   8%|▊         | 1/12 [00:02<00:23,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  17%|█▋        | 2/12 [00:03<00:14,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  33%|███▎      | 4/12 [00:04<00:06,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  58%|█████▊    | 7/12 [00:04<00:02,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  67%|██████▋   | 8/12 [00:05<00:02,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  83%|████████▎ | 10/12 [00:06<00:01,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  92%|█████████▏| 11/12 [00:06<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12/12 [00:09<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "from ragas.metrics.critique import harmfulness\n",
    "\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['OPENAI_API_KEY']\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "from prompts import text_qa_template\n",
    "from simpleRAG import genaration_qa\n",
    "\n",
    "\n",
    "data_list = [\n",
    "    {\n",
    "        'question': \"Tác động hạn chế cạnh tranh là gì\",\n",
    "        'ground_truth': \"Tác động hạn chế cạnh tranh là tác động loại trừ, làm giảm, sai lệch hoặc cản trở cạnh tranh trên thị trường.\",\n",
    "        'answer': \"Tác động hạn chế cạnh tranh là tác động loại trừ, làm giảm, sai lệch hoặc cản trở cạnh tranh trên thị trường.\",\n",
    "        'contexts': [\"France is a country located in Western Europe.\", \"The Eiffel Tower is located in Paris.\"]\n",
    "    },\n",
    "    {\n",
    "        'question': \"Who wrote 'Romeo and Juliet'?\",\n",
    "        'ground_truth': \"William Shakespeare\",\n",
    "        'answer': \"William Shakespeare\",\n",
    "        'contexts': [\"'Romeo and Juliet' is a tragedy written by William Shakespeare.\", \"It was first published in 1597.\"]\n",
    "    },\n",
    "    {\n",
    "        'question': \"What is the chemical symbol for water?\",\n",
    "        'ground_truth': \"H2O\",\n",
    "        'answer': \"H2O\",\n",
    "        'contexts': [\"Water is a chemical compound composed of two hydrogen atoms and one oxygen atom.\", \"It is essential for life on Earth.\"]\n",
    "    }\n",
    "]\n",
    "ds = Dataset.from_list(data_list)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = evaluate(\n",
    "        ds,\n",
    "        metrics=[\n",
    "            context_precision,\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_recall,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    result\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "law_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
