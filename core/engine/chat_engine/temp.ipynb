{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.vector_stores import ElasticsearchStore\n",
    "\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.environ['OPENAI_API_KEY']\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "class ChatEngine:\n",
    "\n",
    "    def __init__(self, documents_path=\"../../data/\", new_indexing=False):\n",
    "        self.vector_store = ElasticsearchStore(\n",
    "                                es_url=\"http://localhost:9200\",\n",
    "                                index_name=\"law_index\",\n",
    "                            )\n",
    "        self.node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "            window_size=3,\n",
    "            window_metadata_key=\"window\",\n",
    "            original_text_metadata_key=\"original_text\",\n",
    "        )\n",
    "        self.documents = SimpleDirectoryReader(documents_path).load_data()\n",
    "        self.sentence_nodes = self.node_parser.get_nodes_from_documents(self.documents)\n",
    "        self.storage_context = StorageContext.from_defaults(vector_store=self.vector_store)\n",
    "        self.index = VectorStoreIndex.from_vector_store(self.vector_store, storage_context=self.storage_context)\n",
    "        if new_indexing:\n",
    "            self.index = VectorStoreIndex(\n",
    "                self.sentence_nodes,\n",
    "                storage_context=self.storage_context,\n",
    "            )\n",
    "\n",
    "\n",
    "    def chat(self, ques=\"Bạn là ai?\"):\n",
    "        query_engine = self.index.as_query_engine()\n",
    "        res =query_engine.query(ques)\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:GET http://localhost:9200/ [status:200 duration:0.022s]\n",
      "GET http://localhost:9200/ [status:200 duration:0.022s]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/law_index/_search [status:200 duration:0.047s]\n",
      "POST http://localhost:9200/law_index/_search [status:200 duration:0.047s]\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "I am someone who is closely related to the party being investigated or the complaining party, has rights or obligations related to the competition case, and has clear grounds to believe they are not impartial when performing their duties.\n"
     ]
    }
   ],
   "source": [
    "r = ChatEngine()\n",
    "print(r.chat())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "law_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
